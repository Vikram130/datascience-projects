
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split

train_data = pd.read_excel('/Train.xlsx')  # Load training data as .xlsx file

target_column = 'PCE'   # Identifying the target column
                       # Identifying the target column# Replace with the actual name of your target column

             # to check if the target column exists in the training dataset
if target_column in train_data.columns:
     # Extracting features and target for training set
    X_train = train_data.drop(target_column, axis=1)
    y_train = train_data[target_column]

    # Load test data
    test_data = pd.read_excel('/Test-2.xlsx')

    # Check if the target column exists in the test dataset
    if target_column in test_data.columns:
        # Extract features and target for testing set
        X_test = test_data.drop(target_column, axis=1)
        y_test = test_data[target_column]

        # Scale the data using StandardScaler
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Logistic Regression
        logistic_model = LogisticRegression()
        logistic_model.fit(X_train_scaled, y_train)
        y_pred_logistic = logistic_model.predict(X_test_scaled)
        accuracy_logistic = accuracy_score(y_test, y_pred_logistic)
        conf_matrix_logistic = confusion_matrix(y_test, y_pred_logistic)

        print("Logistic Regression:")
        print(f"Accuracy (Train): {accuracy_score(y_train, logistic_model.predict(X_train_scaled))}")
        print(f"Accuracy (Test): {accuracy_logistic}")
        print(f"Confusion Matrix:\n{conf_matrix_logistic}")
        feature_importance_lr = logistic_model.coef_[0]
        feature_names = X_train.columns  # Correct definition of feature_names
        feature_importance_lr_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance_lr})
        feature_importance_lr_df = feature_importance_lr_df.sort_values(by='Importance', ascending=False)

        print("\nTop Features in Logistic Regression:")
        print(feature_importance_lr_df.head())

        # Support Vector Machine (SVM)
        svm_model = SVC()
        svm_model.fit(X_train_scaled, y_train)
        y_pred_svm = svm_model.predict(X_test_scaled)
        accuracy_svm = accuracy_score(y_test, y_pred_svm)
        conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)

        print("\nSupport Vector Machine:")
        print(f"Accuracy (Train): {accuracy_score(y_train, svm_model.predict(X_train_scaled))}")
        print(f"Accuracy (Test): {accuracy_svm}")
        print(f"Confusion Matrix:\n{conf_matrix_svm}")



        # Random Forest
        rf_model = RandomForestClassifier()
        rf_model.fit(X_train_scaled, y_train)
        y_pred_rf = rf_model.predict(X_test_scaled)
        accuracy_rf = accuracy_score(y_test, y_pred_rf)
        conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)

        print("\nRandom Forest:")
        print(f"Accuracy (Train): {accuracy_score(y_train, rf_model.predict(X_train_scaled))}")
        print(f"Accuracy (Test): {accuracy_rf}")
        print(f"Confusion Matrix:\n{conf_matrix_rf}")
        feature_importance_rf = rf_model.feature_importances_
        feature_importance_rf_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance_rf})
        feature_importance_rf_df = feature_importance_rf_df.sort_values(by='Importance', ascending=False)

        print("\nTop Features in Random Forest:")
        print(feature_importance_rf_df.head())
    else:
        print(f"Error: '{target_column}' column not found in the test dataset.")
else:
    print(f"Error: '{target_column}' column not found in the training dataset.")





import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt

# Load training data
train_data = pd.read_excel('/Train.xlsx')

# Assuming 'target' is your dependent variable
target_column = 'PCE'

# Extract features and target for training set
X_train = train_data.drop(target_column, axis=1)
y_train = train_data[target_column]

# Load test data
test_data = pd.read_excel('/Test-2.xlsx')

# Extract features and target for test set
X_test = test_data.drop(target_column, axis=1)
y_test = test_data[target_column]

# Build the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions on training and test sets
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# Calculate RMSE for training and test sets
rmse_train = sqrt(mean_squared_error(y_train, y_train_pred))
rmse_test = sqrt(mean_squared_error(y_test, y_test_pred))

# Calculate R2 for training and test sets
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

# Print the results
print(f"RMSE (Training): {rmse_train}")
print(f"RMSE (Test): {rmse_test}")
print(f"R2 Score (Training): {r2_train}")
print(f"R2 Score (Test): {r2_test}")
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="whitegrid")

# Scatter plot for training set
plt.figure(figsize=(10, 6))
plt.scatter(y_train, y_train_pred, color='blue', label='Actual vs. Predicted (Training)')
plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], linestyle='--', color='red', linewidth=2, label='Perfect Prediction')
plt.title('Actual vs. Predicted (Training Set)')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()

# Scatter plot for test set
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_test_pred, color='green', label='Actual vs. Predicted (Test)')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', linewidth=2, label='Perfect Prediction')
plt.title('Actual vs. Predicted (Test Set)')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()
